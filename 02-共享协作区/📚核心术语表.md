# 📚 核心术语表

## 第1章 绪论

### 机器学习 (Machine Learning)
- **定义**: 研究如何通过计算的手段，利用经验（通常是数据）来改善系统自身的性能
- **关键特征**: 从数据中学习规律，用于预测或决策

### 数据集 (Dataset)
- **定义**: 用于机器学习的数据集合
- **组成**: 样本（instance/feature）+ 标签（label）

### 训练集 (Training Set)
- **定义**: 用于训练模型的数据子集
- **用途**: 模型从中学习规律

### 测试集 (Test Set)
- **定义**: 用于评估模型性能的数据子集
- **用途**: 检验模型的泛化能力

### 泛化能力 (Generalization)
- **定义**: 模型在未见过数据上的表现能力
- **重要性**: 衡量模型好坏的核心指标

### 监督学习 (Supervised Learning)
- **定义**: 从带标签的数据中学习的机器学习方法
- **例子**: 分类、回归

### 无监督学习 (Unsupervised Learning)
- **定义**: 从无标签数据中发现结构的学习方法
- **例子**: 聚类、降维

### 半监督学习 (Semi-supervised Learning)
- **定义**: 同时使用有标签和无标签数据进行学习
- **应用场景**: 标签数据稀缺时

## 第2章 模型评估与选择

### 过拟合 (Overfitting)
- **定义**: 模型在训练集上表现很好，但在测试集上表现很差
- **原因**: 模型过于复杂，学习了噪声数据
- **解决方法**: 增加数据、正则化、早停

### 欠拟合 (Underfitting)
- **定义**: 模型在训练集和测试集上表现都不好
- **原因**: 模型过于简单，无法捕捉数据规律
- **解决方法**: 增加模型复杂度、特征工程

### 经验误差 (Empirical Error)
- **定义**: 模型在训练集上的误差
- **用途**: 指导模型参数调整

### 泛化误差 (Generalization Error)
- **定义**: 模型在未知数据上的期望误差
- **重要性**: 真实性能的衡量指标

### 交叉验证 (Cross Validation)
- **定义**: 将数据集分成多份，轮流作为验证集的评估方法
- **常用方法**: k折交叉验证、留一法

### 精确率 (Precision)
- **定义**: 预测为正例中真正为正例的比例
- **公式**: TP / (TP + FP)
- **适用场景**: 对误报敏感的应用

### 召回率 (Recall)
- **定义**: 真实正例中被正确预测的比例
- **公式**: TP / (TP + FN)
- **适用场景**: 对漏报敏感的应用

### F1分数 (F1 Score)
- **定义**: 精确率和召回率的调和平均
- **公式**: 2 × (Precision × Recall) / (Precision + Recall)
- **用途**: 综合评估分类器性能

### ROC曲线 (ROC Curve)
- **定义**: 不同阈值下真正例率与假正例率的关系曲线
- **用途**: 评估分类器的整体性能
- **AUC**: ROC曲线下的面积

## 第3章 线性模型

### 线性回归 (Linear Regression)
- **定义**: 通过线性组合预测连续值的模型
- **数学形式**: y = w₁x₁ + w₂x₂ + ... + b
- **损失函数**: 均方误差 (MSE)

### 对数几率回归 (Logistic Regression)
- **定义**: 用于二分类的线性模型
- **激活函数**: Sigmoid函数
- **输出**: 0到1之间的概率值

### 线性判别分析 (LDA)
- **定义**: 寻找最优投影方向的降维分类方法
- **目标**: 最大化类间距离，最小化类内距离
- **用途**: 分类和特征提取

### 多分类学习 (Multi-class Learning)
- **定义**: 将二分类器扩展到多类别问题
- **策略**: 一对一、一对多、多对多

### 类别不平衡 (Class Imbalance)
- **定义**: 不同类别的样本数量差异很大
- **影响**: 分类器偏向多数类
- **解决方法**: 重采样、代价敏感学习

## 第4章 决策树

### 信息熵 (Information Entropy)
- **定义**: 衡量信息不确定性的指标
- **公式**: H(X) = -∑p(x)log₂p(x)
- **用途**: 决策树划分依据

### 信息增益 (Information Gain)
- **定义**: 划分前后信息熵的减少量
- **用途**: ID3算法的划分标准

### 信息增益比 (Gain Ratio)
- **定义**: 信息增益与分裂信息的比值
- **用途**: C4.5算法的划分标准，克服信息增益偏向多值特征的问题

### 基尼指数 (Gini Index)
- **定义**: 衡量数据不纯度的指标
- **用途**: CART算法的划分标准
- **公式**: Gini = 1 - ∑p²

### 剪枝 (Pruning)
- **定义**: 减少决策树复杂度的技术
- **类型**: 预剪枝、后剪枝
- **目的**: 防止过拟合

## 第5章 神经网络

### 感知机 (Perceptron)
- **定义**: 最简单的神经网络单元
- **组成**: 输入、权重、偏置、激活函数
- **用途**: 线性分类

### 多层感知机 (MLP)
- **定义**: 包含输入层、隐藏层、输出层的神经网络
- **特点**: 可以学习非线性关系
- **训练**: 反向传播算法

### 激活函数 (Activation Function)
- **定义**: 为神经网络引入非线性的函数
- **常见类型**: Sigmoid、Tanh、ReLU、LeakyReLU
- **作用**: 决定神经元是否激活

### 反向传播 (Backpropagation)
- **定义**: 训练神经网络的核心算法
- **原理**: 从输出层向输入层传播误差
- **用途**: 更新网络权重

### 梯度消失 (Vanishing Gradient)
- **定义**: 在深层网络中梯度逐层减小的问题
- **原因**: 激活函数饱和、网络过深
- **解决方法**: ReLU激活函数、残差连接

### 梯度爆炸 (Exploding Gradient)
- **定义**: 在深层网络中梯度逐层增大的问题
- **原因**: 权重初始化不当
- **解决方法**: 权重归一化、梯度裁剪

## 第6章 支持向量机

### 支持向量 (Support Vector)
- **定义**: 位于最大间隔边界上的样本点
- **重要性**: 决定分类边界的关键样本

### 最大间隔 (Maximum Margin)
- **定义**: 支持向量到分类边界的最小距离
- **目标**: 最大化这个间隔
- **优点**: 提高泛化能力

### 核函数 (Kernel Function)
- **定义**: 将低维数据映射到高维空间的函数
- **常用核**: 线性核、多项式核、高斯核(RBF)
- **作用**: 处理非线性分类问题

### 软间隔 (Soft Margin)
- **定义**: 允许部分样本违反分类约束的SVM
- **参数**: C（惩罚系数）
- **作用**: 处理线性不可分情况

### 对偶问题 (Dual Problem)
- **定义**: 将原问题转化为对偶形式的优化问题
- **优点**: 引入核函数、计算效率更高
- **求解**: 使用拉格朗日乘子法